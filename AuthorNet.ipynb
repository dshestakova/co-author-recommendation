{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa429415-77f3-43ac-b815-ad5853120351",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66afb00c-0e02-4c4f-9e38-dcba96a3db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalex import Works, Authors, Sources, Institutions, Topics, Publishers, Funders\n",
    "import pyalex\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import typing as tp\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import os\n",
    "pyalex.config.email = \"v.veselov1@g.nsu.ru\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f575c0-e8ad-4328-90a9-5f956577ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data_to_pqt.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bc60c5-2af0-4be9-bbef-279d477c3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_id = data['Article OpenAlex ID'].apply(lambda x: x.split('/')[-1]) # получаем id статей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75bb729a-a5ba-4c1f-b3d2-5ff364283732",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_id = data['Author OpenAlex ID'].apply(lambda x: x.split('/')[-1]).unique() # получаем id авторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8694d090-4504-4d80-96a8-a97ec3b8a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_authors_openalex(start_it: int=0) -> tp.Dict:\n",
    "    \"\"\"Парсинг авторов с openalex.\n",
    "\n",
    "    Args:\n",
    "        start_it (int): стартовая итерация для парсинга.\n",
    "\n",
    "    Returns:\n",
    "        save_dict_authors (Dict[int, Dict]): сохраненные данные по авторам.\n",
    "        \n",
    "    \"\"\"\n",
    "    save_dict_authors = {}\n",
    "    for it, id in tqdm(enumerate(authors_id), total=len(authors_id)):\n",
    "        if it < start_it:\n",
    "            continue\n",
    "        if id not in save_dict_authors:\n",
    "            author = Authors()[id]\n",
    "            try:\n",
    "                save_dict_authors[id] = author\n",
    "            except:\n",
    "                print(f'exception: author {id} not found!')\n",
    "                continue\n",
    "                \n",
    "        if it % 100 == 0 and it != start_it:\n",
    "            pd.to_pickle(save_dict_authors, f'save_dict_authors_{it}.pkl')\n",
    "    return save_dict_authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7cba2e9-6135-40f1-b07d-bfdba62210d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_papers_openalex() -> tp.Dict:\n",
    "    \"\"\"Парсинг статей с openalex.\n",
    "\n",
    "    Args:\n",
    "        start_it (int): стартовая итерация для парсинга.\n",
    "\n",
    "    Returns:\n",
    "        save_dict_papers (Dict[int, Dict]): сохраненные данные по статьям.\n",
    "        \n",
    "    \"\"\"\n",
    "    save_dict_papers = {}\n",
    "    for it, id in tqdm(enumerate(articles_id.unique()), total=len(articles_id.unique())):\n",
    "        if it < start_it:\n",
    "            continue\n",
    "        if id not in save_dict_papers:\n",
    "            paper = Works()[id]\n",
    "            try:\n",
    "                save_dict_papers[id] = paper\n",
    "            except:\n",
    "                print(f'exception: paper {id} not found!')\n",
    "                continue\n",
    "                \n",
    "        if it % 3000 == 0 and it != 0:\n",
    "            pd.to_pickle(save_dict_papers, f'save_dict_papers_{it}.pkl')\n",
    "    pd.to_pickle(save_dict_papers, f'save_dict_papers.pkl')\n",
    "    return save_dict_papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fbaec58-0029-4693-8e07-8c9cd50e1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем спаршенные данные \n",
    "\n",
    "saved_papers = pd.read_pickle('save_dict_papers_70000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f313fbb-8afd-447f-9b7d-1248ee65d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_authors_rel(saved_papers: tp.Dict) -> tp.Dict:\n",
    "    \"\"\"Выделение основных доменов данных.\n",
    "\n",
    "    Args:\n",
    "        saved_papers (Dict[int, Dict]): сохраненные данные по статьям.\n",
    "\n",
    "    Returns:\n",
    "        paper_authors (Dict[int, Dict[str, Optional]]): словарь основных доменов данных.\n",
    "\n",
    "    \"\"\"\n",
    "    paper_authors = {}\n",
    "    k = 0\n",
    "    for id in tqdm(saved_papers):\n",
    "        authorships = saved_papers[id]['authorships']\n",
    "        authors = []\n",
    "        aff = []\n",
    "        paper_authors[id] = {}\n",
    "        try:\n",
    "            for auth in authorships:\n",
    "                author = auth['author']['id'].split('/')[-1]\n",
    "                af = auth['raw_affiliation_strings']\n",
    "                authors.append(author)\n",
    "                aff.extend(af)\n",
    "            paper_authors[id]['title'] = saved_papers[id]['title']\n",
    "            paper_authors[id]['authors'] = authors\n",
    "            paper_authors[id]['authors_affiliations'] = aff\n",
    "            paper_authors[id]['topics'] = [(i['display_name'], i['score'])  for i in saved_papers[id]['topics'] if 'display_name' in i] \n",
    "            paper_authors[id]['keywords'] = [(i['display_name'], i['score'])  for i in saved_papers[id]['keywords'] if 'display_name' in i]  \n",
    "            if saved_papers[id]['primary_topic'] is not None:\n",
    "                paper_authors[id]['prim_topic'] = saved_papers[id]['primary_topic']['display_name']\n",
    "                paper_authors[id]['subfield'] = saved_papers[id]['primary_topic']['subfield']['display_name']\n",
    "                paper_authors[id]['field'] =  saved_papers[id]['primary_topic']['field']['display_name']\n",
    "                paper_authors[id]['domain'] = saved_papers[id]['primary_topic']['domain']['display_name']\n",
    "            else:\n",
    "                k+=1\n",
    "        except:\n",
    "            print(id)\n",
    "            continue\n",
    "        \n",
    "        paper_authors[id]['pub_date'] = dt.datetime.strptime(f\"{(saved_papers[id]['publication_date'])}\",  \"%Y-%m-%d\")\n",
    "        \n",
    "    return paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df586ddb-0814-40e5-a56e-7dc1fdf6fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                   | 1352/77002 [00:00<00:33, 2270.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W3010671326\n",
      "W2887469692\n",
      "W2918172693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                 | 4845/77002 [00:01<00:15, 4621.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2807156318\n",
      "W4226308094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 77002/77002 [00:05<00:00, 15100.17it/s]\n"
     ]
    }
   ],
   "source": [
    "paper_authors = create_paper_authors_rel(saved_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36da1e66-3500-44cc-8880-011859817cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_exist_table(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Дополняем существующие данные новыми доменами.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): исходные данные без доменов.\n",
    "        \n",
    "    Outputs:\n",
    "        data (DataFrame): данные c доменами.\n",
    "    \"\"\"\n",
    "    data['topics'] = None\n",
    "    data['keywords'] = None\n",
    "    for i, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        try:\n",
    "            paper_id = row['Article OpenAlex ID'].split('/')[-1]\n",
    "            if paper_id in paper_authors:\n",
    "                data.at[i, 'pub_date'] = paper_authors[paper_id]['pub_date']\n",
    "                data.at[i, 'keywords'] = [i[0] for i in paper_authors[paper_id]['keywords']]\n",
    "                data.at[i, 'topics'] = [i[0] for i in paper_authors[paper_id]['topics']]\n",
    "                try: \n",
    "                    data.at[i,'prim_topic'] = paper_authors[paper_id]['prim_topic']\n",
    "                    data.at[i,'subfield'] = paper_authors[paper_id]['subfield']\n",
    "                    data.at[i,'field'] =  paper_authors[paper_id]['field']\n",
    "                    data.at[i,'domain'] = paper_authors[paper_id]['domain']\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            print(i)\n",
    "            continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3d66cb8-adc5-457b-916f-fa089b57497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Author OpenAlex ID'] != 'https://openalex.org/A5005891681'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24589c75-6922-45d2-b891-e89bfe3f121d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                   | 1540/160755 [00:02<04:14, 626.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413\n",
      "1424\n",
      "1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▉                                   | 4150/160755 [00:07<03:58, 655.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4070\n",
      "4085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                  | 6377/160755 [00:10<04:34, 562.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                  | 6752/160755 [00:11<04:04, 630.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 160755/160755 [03:07<00:00, 857.59it/s]\n"
     ]
    }
   ],
   "source": [
    "data = update_exist_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ff21ff9-6224-46d1-98db-7cefedc32325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем времена начала и конца периода, в котором будем рассматривать матрицу взаимодействий C_ij\n",
    "\n",
    "t_start, t_end = dt.datetime.strptime(\"2012-02-01\", \"%Y-%m-%d\"), dt.datetime.strptime(\"2023-06-06\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "aa387ee5-57ad-4d4b-bf73-2dbfc6b7657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем пропуски\n",
    "\n",
    "data_notna = data[~data.topics.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "888cab42-7719-4ce3-8bcb-b812a3cbf884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_author = 'Vitali M. Volosi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "4d0ffcd7-1e02-4123-91d8-05bf842e0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_names = data_notna[data_notna['Author name'] == example_author]['Author name'].sample(frac=1)\n",
    "# for i in shuffled_names.index:\n",
    "#     shuffled_names[i] = shuffled_names[i] + \"_1\" if i % 2 != 0 else shuffled_names[i] + \"_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "0b14d858-6baf-419f-8c2d-7c79240ec416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_notna.loc[data_notna['Author name'] == example_author, 'Author name'] = shuffled_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "ae6d41da-58dc-469d-b5e1-8228af91da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_notna.loc[data_notna['Author name'] == example_author + \"_1\", 'Author OpenAlex ID'] = data_notna.loc[data_notna['Author name'] == example_author + \"_1\", 'Author OpenAlex ID'] + '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c43f5544-11bd-4e39-949f-5aa84881e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем id всех авторов из таблицы\n",
    "\n",
    "all_authors = list(np.unique(data_notna['Author OpenAlex ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1b7750f1-aec3-4b31-bce7-b5955a35a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем отношение между статьями, авторами, временем публикации \n",
    "\n",
    "authors_rel = data_notna.groupby(['Article OpenAlex ID', 'pub_date'])['Author OpenAlex ID'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "06713141-a86e-486f-b8cc-78660aba6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# текущее время\n",
    "t_current = dt.datetime.now()\n",
    "\n",
    "# перевод даты в месяца, года\n",
    "in_months = lambda x: x.year * 12 + x.month\n",
    "in_years = lambda x: x.year\n",
    "\n",
    "# подсчет разницы между датами в месяцах, годах\n",
    "to_month = lambda a,b: b.month - a.month + (b.year - a.year)*12\n",
    "to_year = lambda a, b: b.year - a.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "02a1573f-abc0-4757-af93-255707ce439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coop_strength_matrix(t_start: dt.datetime, t_end: dt.datetime, time_func_in=in_months) -> tp.Tuple[np.array, np.array]:\n",
    "    \"\"\"Создаем матрицу коопераций с_ij.\n",
    "    \n",
    "    Args:\n",
    "        t_start (Datetime): время начала взаимодействий.\n",
    "        t_end (Datetime): время конца взаимодействий.\n",
    "        time_func (Callable[Datetime, int]): перевод времени в года или месяцы.\n",
    "\n",
    "    Returns:\n",
    "        first_communicate, authors_matrix * mask_matrix (Tuple[Array, Array]): матрицы первых взаимодействий авторов в годах/месяцах и силы коопераций между авторами. \n",
    "    \"\"\"\n",
    "    authors_matrix = np.zeros((len(all_authors), len(all_authors)))\n",
    "    mask_matrix = np.zeros((len(all_authors), len(all_authors)))\n",
    "    first_communicate = np.ones((len(all_authors), len(all_authors))) * 1e6\n",
    "    for it, aus in tqdm(enumerate(authors_rel.values), total=len(authors_rel.values)):\n",
    "        for a in aus:\n",
    "            for b in aus:\n",
    "                if t_start <= authors_rel.index[it][1] <= t_end: \n",
    "                    f_com = first_communicate[all_authors.index(a), all_authors.index(b)]\n",
    "                    if  f_com > time_func_in(authors_rel.index[it][1]):\n",
    "                        first_communicate[all_authors.index(a), all_authors.index(b)] = time_func_in(authors_rel.index[it][1])\n",
    "    # print(first_communicate)\n",
    "    for it, aus in tqdm(enumerate(authors_rel.values), total=len(authors_rel.values)):\n",
    "        for a in aus:\n",
    "            for b in aus:\n",
    "                if a == b:\n",
    "                    mask_matrix[all_authors.index(a), all_authors.index(b)] = 1\n",
    "                if t_start <= authors_rel.index[it][1] <= t_end:\n",
    "                    if a == b: continue\n",
    "                    f_com = first_communicate[all_authors.index(a), all_authors.index(b)]\n",
    "                    authors_matrix[all_authors.index(a), all_authors.index(b)] += (time_func_in(authors_rel.index[it][1]) - f_com) / (time_func_in(t_current) - f_com) if f_com != 1e-6 else 0  \n",
    "                    mask_matrix[all_authors.index(a), all_authors.index(b)] = 1\n",
    "    # print(mask_matrix)\n",
    "    print(mask_matrix.sum(axis=1).max())\n",
    "    authors_matrix = (lambda x: 1 / (1 + np.e**(-x)))(authors_matrix)\n",
    "    authors_matrix += np.eye(len(authors_matrix)) / 2\n",
    "    \n",
    "                    \n",
    "                \n",
    "    return  first_communicate, authors_matrix * mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "357b9737-bf19-445e-a240-6a3e6fb106f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 76997/76997 [00:29<00:00, 2596.25it/s]\n",
      "100%|███████████████████████████████████| 76997/76997 [00:56<00:00, 1357.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.0\n"
     ]
    }
   ],
   "source": [
    "first_coop, matrix_coop = coop_strength_matrix(t_start, t_end, time_func_in=in_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "20dd3115-3f38-48d0-89cf-e0bad7d9802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2author = dict(zip(data_notna['Author OpenAlex ID'], data_notna['Author name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b06c5bfa-3e87-48cd-9b2a-5f877711535a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authors_ = list(map(lambda x: id2author[x], all_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "d466221f-bd34-4b10-af57-1fb1852c6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cоздаем отношение автор - вектор признаков (b_i = (b1,..., b6) ). \n",
    "\n",
    "author_vectors = data_notna.groupby('Author name').agg({'keywords': lambda x: list(set(sum(x, []))),\n",
    "                                                        'topics': lambda x: list(set(sum(x, []))),\n",
    "                                                        'prim_topic': lambda x: list(set(x)),\n",
    "                                                        'subfield': lambda x: list(set(x)),\n",
    "                                                        'field': lambda x: list(set(x)),\n",
    "                                                        'domain': lambda x: list(set(x))\n",
    "                                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "8bfa974f-d73d-4d27-9486-e9cd457ea6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairwise_score_matrix(author_vectors: pd.DataFrame, authors: tp.List) -> pd.DataFrame:\n",
    "    \"\"\"Создаем матрицу сходства по атрибутам S_ij.\n",
    "\n",
    "    Args:\n",
    "        author_vectors (DataFrame): авторы и их атрибуты.\n",
    "        authors (List): все авторы.\n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    authors_pairwise_score_matrix = pd.DataFrame(np.zeros((len(authors), len(authors))), columns=authors, index=authors)\n",
    "    for a_name_1, a_vec_1 in tqdm(author_vectors.iterrows(), total=author_vectors.shape[0]):\n",
    "        for a_name_2, a_vec_2 in author_vectors.iterrows(): \n",
    "            pairwise_score = 0\n",
    "            for feature_1, feature_2 in zip(a_vec_1, a_vec_2):\n",
    "                cnt_features = max(len(feature_1), len(feature_2))\n",
    "                cnt_eq_features = len(set(feature_1) & set(feature_2))\n",
    "                feature_score = cnt_eq_features / cnt_features if cnt_features > 0 else 0\n",
    "                pairwise_score += feature_score\n",
    "            authors_pairwise_score_matrix.loc[a_name_1, a_name_2] = pairwise_score / 6\n",
    "    return authors_pairwise_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f147be95-b5a8-4b84-95c5-dc3d2f506eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6959/6959 [38:51<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "authors_pairwise_score_matrix = create_pairwise_score_matrix(author_vectors, authors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe592e06-a6b1-470d-b636-f3ea81e57f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_pairwise_score_matrix.to_csv('authors_pairwise_score_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffb368-b481-4a83-80a4-a226ef1abf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_pairwise_score_matrix.to_csv('matrix_S.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "98718a67-96eb-435e-b251-17cadc406b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_pairwise_score_matrix = pd.read_csv('authors_pairwise_score_matrix.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8e55c9dc-d134-4d5b-ab9a-7c4f67c1adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_pairwise_score_matrix.index = authors_pairwise_score_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "1c96ae11-4f6f-4a2d-8520-2d421b2c8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = authors_pairwise_score_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "85bbe045-cd8b-4687-98ef-550dd7b7af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_enhance = S / S.sum(axis=1).max() + (np.eye(len(S)) -  S / S.sum(axis=1).max() * np.eye(len(S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "108a4ce4-8537-4548-8f4c-cad049625433",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.5\n",
    "W = (1-d)*S_enhance + d*matrix_coop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b841d2f1-3ac3-4b42-bb7e-f5511af3d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_frame = pd.DataFrame(data=W, index=authors_, columns=authors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "4538239e-c27f-4ef8-83f0-93d1b47d70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_first_last_store(data: pd.DataFrame) -> tp.Tuple[tp.Dict, tp.Dict]:\n",
    "    \"\"\"Подсчет появления атрибутов автора в первый и последний момент времени.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): данные авторов по их статьям и атрибутам.\n",
    "\n",
    "    Returns:\n",
    "        author_first_store, author_last_store (Tuple[Dict, Dict]): словари появления ключевых слов у авторов в первый и последний моменты времени.\n",
    "    \"\"\"\n",
    "    author_first_store = {}\n",
    "    author_last_store = {}\n",
    "    list_types = ['keywords', 'topics']\n",
    "    el_types = ['prim_topic', 'subfield', 'field', 'domain']\n",
    "    for i, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        author_name = row['Author name']\n",
    "        if author_name not in author_first_store:\n",
    "            author_first_store[author_name] = {}\n",
    "            author_last_store[author_name] = {}\n",
    "            \n",
    "        for types in list_types:\n",
    "            \n",
    "            if types not in author_first_store[author_name]:\n",
    "                author_first_store[author_name][types] = {} \n",
    "                author_last_store[author_name][types] = {} \n",
    "                \n",
    "            for t in row[types]:\n",
    "                if t in author_first_store[author_name][types]:\n",
    "                    \n",
    "                    if row['pub_date'] < author_first_store[author_name][types][t]:\n",
    "                        author_first_store[author_name][types][t] = row['pub_date']\n",
    "                        \n",
    "                    if row['pub_date'] > author_last_store[author_name][types][t]:\n",
    "                        author_last_store[author_name][types][t] = row['pub_date']\n",
    "                else:\n",
    "                    author_first_store[author_name][types].update({t: row['pub_date']})\n",
    "                    author_last_store[author_name][types].update({t: row['pub_date']})\n",
    "            \n",
    "        for type in el_types:\n",
    "            \n",
    "            if type not in author_first_store[author_name]:\n",
    "                author_first_store[author_name][type] = {}\n",
    "                author_last_store[author_name][type] = {} \n",
    "                \n",
    "            if row[type] in author_first_store[author_name][type]: \n",
    "                \n",
    "                if row['pub_date'] < author_first_store[author_name][type][row[type]]:\n",
    "                    author_first_store[author_name][type][row[type]] = row['pub_date']\n",
    "    \n",
    "                if row['pub_date'] > author_last_store[author_name][type][row[type]]:\n",
    "                        author_last_store[author_name][type][row[type]] = row['pub_date']\n",
    "            \n",
    "            else:\n",
    "                author_first_store[author_name][type].update({row[type]: row['pub_date']})\n",
    "                author_last_store[author_name][type].update({row[type]: row['pub_date']})\n",
    "    return author_first_store, author_last_store\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "38721307-fad2-47f4-a188-6105808ed713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 129433/129433 [00:10<00:00, 12134.45it/s]\n"
     ]
    }
   ],
   "source": [
    "author_first_store, author_last_store = get_author_first_last_store(data_notna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "31e044f0-6a86-484e-8656-37a94c446804",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pub = data_notna.groupby('Author name')['pub_date'].agg(min).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "d104be98-4c9f-461b-81fe-45026d1c8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rele(author_name: str, attr: str, subattr: str, time_func_to=to_month) -> float:\n",
    "    \"\"\"Подсчет relevance.\n",
    "\n",
    "    Args:\n",
    "        author_name (str): автор, для которого считается reletion.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца. \n",
    "\n",
    "    Returns:\n",
    "        res (float): значение relevance для автора при определенном атрибуте и отрезке времени.\n",
    "    \"\"\"\n",
    "    res = (time_func_to(author_first_store[author_name][attr][subattr], t_current) + 1) \n",
    "    delim = (time_func_to(first_pub[author_name], t_current) + 1)\n",
    "    if delim == 0:\n",
    "        print(f\"RELE: Error in pub_date: {author_name, attr, subattr}\")\n",
    "        return 0\n",
    "    res /= delim\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "11d6fc32-e2c7-4d42-9f27-59f225cba591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox(author_name: str, attr: str, subattr: str, time_func_to=to_month) -> float:\n",
    "    \"\"\"Подсчет proximity.\n",
    "\n",
    "    Args:\n",
    "        author_name (str): автор, для которого считается reletion.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца. \n",
    "\n",
    "    Returns:\n",
    "        1 / delim (float): значение proximity для автора при определенном атрибуте и отрезке времени.\n",
    "    \"\"\"\n",
    "    delim = (time_func_to(author_last_store[author_name][attr][subattr], t_current)+1)\n",
    "    if delim == 0:\n",
    "        print(f\"PROX: Error in pub_date: {author_name, attr, subattr}\")\n",
    "        return 0\n",
    "    return 1 / delim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ed32952c-1afd-4220-be7d-b7cbfda41769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(psi: float, author_name: str, attr: str, subattr: str, time_func_to=to_month) -> float:\n",
    "    \"\"\"Подсчет веса вершины автора.\n",
    "\n",
    "    Args:\n",
    "        psi (float): параметр, отвечающий за приоритет между relevance и proximity. \n",
    "        author_name (str): автор, для которого считается reletion.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца. \n",
    "\n",
    "    Returns:\n",
    "        (float): линейная комбинация, отвечающая за вес вершины. \n",
    "    \"\"\"\n",
    "    # print(f'RELE {rele(author_name, attr, subattr)} PROX {prox(author_name, attr, subattr)}')\n",
    "    return psi * rele(author_name, attr, subattr, time_func_to) + (1 - psi) * prox(author_name, attr, subattr, time_func_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a711400b-d68f-4543-8321-40724b8b129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adj_matrix(authors: tp.List, all_authors: tp.List, authors_rel: pd.Series) -> np.array:\n",
    "    \"\"\"Подсчет матрицы смежности.\n",
    "\n",
    "    Args:\n",
    "        authors (List): список всех авторов с их ФИО.\n",
    "        all_authors (List): список всех авторов с их Author ID.\n",
    "        authors_rel (Series): данные, отражающие связь между статьей, датой публикации и авторами статьи.\n",
    "\n",
    "    Returns:\n",
    "        adjacency_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "    \"\"\"\n",
    "    adjacency_matrix = np.zeros((len(authors), len(authors)))\n",
    "    for it, aus in tqdm(enumerate(authors_rel.values), total=len(authors_rel.values)):\n",
    "        for a in aus:\n",
    "            for b in aus:\n",
    "                adjacency_matrix[all_authors.index(a), all_authors.index(b)] = 1\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "7ac4a894-5f75-4903-a438-13c3b280afb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 76997/76997 [00:30<00:00, 2518.83it/s]\n"
     ]
    }
   ],
   "source": [
    "adjacency_matrix = calculate_adj_matrix(authors_, all_authors, authors_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8b2ab746-b650-4bc1-81cd-85157f6f44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_ = list(map(lambda x: id2author[x], all_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "120095ca-055d-45ff-b87a-a7d1196c99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = pd.DataFrame(adjacency_matrix, index=authors_, columns=authors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "970549a6-d2d3-4dfe-a0c2-a6af7dccd93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_a_func(author: str, adj_matrix: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Подсчет смежных к автору авторов по совместным публикациям.\n",
    "\n",
    "    Args:\n",
    "        author (str): автор, для которого строятся смежные авторы.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "\n",
    "    Returns:\n",
    "        (Series): смежные авторы с заданным автором.\n",
    "    \"\"\"\n",
    "    return adj_matrix.loc[author][adj_matrix.loc[author] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "5813200b-2c4b-498b-8993-153777dc785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(author: str, attr: str, subattr: str, adj_matrix: np.array, psi: float, time_func_to=to_month) -> float:\n",
    "    \"\"\"Подсчет Quality. Чем выше качество узла, тем более он связан с другими узлами и имеет наибольший вес относительно атрибута.\n",
    "\n",
    "    Args:\n",
    "        author (str): автор, для которого считается Quality.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "        psi (float): параметр, отвечающий за приоритет между relevance и proximity. \n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца.\n",
    "\n",
    "    Returns:\n",
    "        (float): значение Quality для автора при определенном атрибуте.\n",
    "        \n",
    "    \"\"\"\n",
    "    N_a = N_a_func(author, adj_matrix)\n",
    "    numeric = 0\n",
    "    for a_1 in N_a.index:\n",
    "        for a_2 in N_a.index:\n",
    "            if a_1 == a_2: continue\n",
    "            numeric += adj_matrix.loc[a_1, a_2] == 1\n",
    "    weight_list = []\n",
    "    return numeric / adj_matrix.sum().sum() * weight(psi, author, attr, subattr, time_func_to)\n",
    "    # \n",
    "    # * np.mean(weight_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "b14154e2-e089-47ec-8454-1dabad7dfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IA(a_i: str, a_j: str, adj_matrix: np.array) -> tp.List:\n",
    "    \"\"\"Влияние между двумя узлами. Задает расширение существующего сообщества новыми узлами.\n",
    "\n",
    "    Args: \n",
    "        a_i (str): i-й автор.\n",
    "        a_j (str): j-й автор.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "\n",
    "    Returns:\n",
    "        (List): список авторов, являющихся смежными для двух авторов.\n",
    "    \"\"\"\n",
    "    return list(set(N_a_func(a_i, adj_matrix).index) & (set(N_a_func(a_j, adj_matrix).index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f329d69a-ff8c-4620-982e-1b79b2a22dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_IA(a_i: str, a_j: str, adj_matrix: np.array) -> float:\n",
    "    \"\"\"Плотность зоны влияния между узлами показывает, есть ли связи с узлами, которые потенциально могут находиться в рекомендуемом сообществе.\n",
    "\n",
    "    Args: \n",
    "        a_i (str): i-й автор.\n",
    "        a_j (str): j-й автор.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "\n",
    "    Returns:\n",
    "        (float): степень связи между узлами, которые являются смежными для двух авторов.\n",
    "    \"\"\"\n",
    "    ia_node = IA(a_i, a_j, adj_matrix)\n",
    "    if len(ia_node) <= 1:\n",
    "        return 0\n",
    "    numeric = 0\n",
    "    for a_1 in ia_node:\n",
    "        for a_2 in ia_node:\n",
    "            if a_1 == a_2: continue\n",
    "            numeric += adj_matrix.loc[a_1, a_2] == 1\n",
    "\n",
    "    return numeric / (len(ia_node)) / (len(ia_node) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "97de9fb7-64a4-4872-a4f1-051335e4d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NRS(a_i: str, a_j: str, attr: str, subattr: str, adj_matrix: np.array, S_matrix: np.array, psi: float, time_func_to=to_month) -> float:\n",
    "    \"\"\"Сила связи между двумя узлами.\n",
    "\n",
    "    Args:\n",
    "        a_i (str): i-й автор.\n",
    "        a_j (str): j-й автор.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "        S_matrix (Array): матрица схожести авторов по атрибутам.\n",
    "        psi (float): параметр, отвечающий за приоритет между relevance и proximity. \n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца.\n",
    "        \n",
    "    Returns:\n",
    "        (float): cила связи между двумя узлами.\n",
    "    \"\"\"\n",
    "    return S_matrix.loc[a_i, a_j] * D_IA(a_i, a_j, adj_matrix) * sum([Q(a, attr, subattr, adj_matrix, psi, time_func_to) for a in IA(a_i, a_j, adj_matrix) if subattr in author_first_store[a][attr]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "5ff68c59-36cd-4551-adae-35a84aa309ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate(author, attr, subattr, adj_matrix, S_matrix, psi, time_func_to=to_month) -> str:\n",
    "    \"\"\"Выбор центрального узла-кандидата сообщества.\n",
    "\n",
    "    Args:\n",
    "        author (str): автор, для которого считается Quality.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "        S_matrix (Array): матрица схожести авторов по атрибутам.\n",
    "        psi (float): параметр, отвечающий за приоритет между relevance и proximity. \n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца.\n",
    "        \n",
    "    Returns:\n",
    "        (str): центральный узел-кандидат.\n",
    "    \"\"\"\n",
    "    N_a_author = N_a_func(author, adj_matrix)\n",
    "    mass = Q(author, attr, subattr, adj_matrix, psi, time_func_to)\n",
    "    max_nrs = 0\n",
    "    candidate = author\n",
    "    for v in N_a_author.index:\n",
    "        if v == author or subattr not in author_first_store[v][attr]: continue\n",
    "        if Q(v, attr, subattr, adj_matrix, psi, time_func_to) > mass:\n",
    "            nrs_current = NRS(author, v, attr, subattr, adj_matrix, S_matrix, psi, time_func_to)\n",
    "            if nrs_current > max_nrs:\n",
    "                max_nrs = nrs_current\n",
    "                candidate = v\n",
    "    return candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "ce4e5e01-1056-4bfa-a164-509ef34bc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_detecting(author: str, attr: str, subattr: str, adj_matrix: np.array, S_matrix: np.array, psi: float, time_func_to=to_month) -> str:\n",
    "    \"\"\"Выбор центрального узла.\n",
    "\n",
    "    Args:\n",
    "        author (str): автор, для которого считается Quality.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "        S_matrix (Array): матрица схожести авторов по атрибутам.\n",
    "        psi (float): параметр, отвечающий за приоритет между relevance и proximity. \n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца.\n",
    "        \n",
    "    Returns:\n",
    "        (str): центральный узел целевого сообщества.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        candi = get_candidate(author, attr, subattr, adj_matrix, S_matrix, psi, time_func_to)\n",
    "        if candi == author:\n",
    "            break\n",
    "        else:\n",
    "            author = candi\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "d4c98751-c502-4da8-bf18-0cf0861cfbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "author2id = {v: k for k, v in id2author.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "38e3bd78-a78a-4213-a627-606a56ba33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_a2(C: tp.List , adj_matrix: np.array) -> tp.List:\n",
    "    \"\"\"Подсчет соседей сообщества C.\n",
    "    \n",
    "    Args:\n",
    "        C (List): авторы сообщества C.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "    \n",
    "    Returns:\n",
    "        (List): соседи сообщества C.\n",
    "    \"\"\"\n",
    "    conj_C = []\n",
    "    for c in C:\n",
    "        conj_C = conj_C + list(set(N_a_func(c, adj_matrix).index) - set(C))\n",
    "    return list(set(conj_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "137a4f4c-15bd-4378-9805-5a69166dc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IA_2(v: str, C: tp.List, adj_matrix: np.array) -> tp.List:\n",
    "    \"\"\"Область влияния между сообществом C и его соседом v. \n",
    "    \n",
    "    Args:\n",
    "        v (str): автор, сосед сообщества C. \n",
    "        C (List): авторы сообщества C.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "    \n",
    "    Returns:\n",
    "        (List): список авторов, являющихся смежными для сообщества и автора.\n",
    "    \"\"\"\n",
    "    # if v not in N_a2(C):\n",
    "    #     return list()\n",
    "    # print('====')\n",
    "    # print(C)\n",
    "    # print(N_a_func(v).index)\n",
    "    # print(list(set(C) & set(N_a_func(v).index)))\n",
    "    return list(set(C) & set(N_a_func(v, adj_matrix).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "cd4cdda8-9dc3-45d5-bb29-1a1e148995b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_IA_2(v, C, adj_matrix):\n",
    "    \"\"\"Плотность зоны влияния между сообществом и узлом показывает, есть ли связи с узлами, которые потенциально могут находиться в рекомендуемом сообществе.\n",
    "\n",
    "    Args: \n",
    "        a_i (str): i-й автор.\n",
    "        a_j (str): j-й автор.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "\n",
    "    Returns:\n",
    "        (float): степень связи между узлами, которые являются смежными для двух авторов.\n",
    "    \"\"\"\n",
    "    ia_node = IA_2(v, C, adj_matrix)\n",
    "    numeric = 0\n",
    "    for a_1 in ia_node:\n",
    "        for a_2 in ia_node:\n",
    "            numeric += adj_matrix.loc[a_1, a_2] == 1\n",
    "    return numeric / (len(ia_node)) / (len(ia_node) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "dfab7c3a-6520-4202-bc48-350a06bb4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRS(v: str, C: tp.List, attr: str, subattr: str, adj_matrix: np.array, S_matrix: np.array, psi: float, time_func_to=to_month) -> float:\n",
    "    \"\"\"Сила отношения сообщества С c автором v.\n",
    "\n",
    "    Args:\n",
    "        v (str): автор, сосед сообщества C. \n",
    "        C (List): авторы сообщества C.\n",
    "        attr (str): надатрибут.\n",
    "        subattr (str): атрибуты, принадлежащие надатрибуту.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "        S_matrix (Array): матрица схожести авторов по атрибутам.\n",
    "        psi (float): параметр, отвечающий за приоритет между relevance и proximity. \n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца.\n",
    "\n",
    "    Returns:\n",
    "        (float): Сила отношения сообщества С c автором v.   \n",
    "    \"\"\"\n",
    "    return np.mean([S_matrix.loc[v, c] for c in C]) * D_IA_2(v, C, adj_matrix) * sum([Q(a, attr, subattr, adj_matrix, psi, time_func_to) for a in IA_2(v, C, adj_matrix) if subattr in author_first_store[a][attr]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "168f544f-6f05-4006-9516-c577dd5982c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = 'keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "0f641a0b-3336-4553-9f76-c3086f4ce360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_recommendation(core_member: str, adj_matrix: np.array, S_matrix: np.array, psi: float, time_func_to=to_month) -> tp.List:\n",
    "    \"\"\"Алгоритм расширения сообщества. Дополняет центральный узел узлами двумя способами: NRS и CRS. \n",
    "\n",
    "    Args: \n",
    "        core_member (str): автор, для которого строится рекомендация новых авторов и расширение сообщества.\n",
    "        adj_matrix (Array): матрица смежности авторов по их публикациям.\n",
    "        S_matrix (Array): матрица схожести авторов по атрибутам.\n",
    "        psi (float): параметр, отвечающий за приоритет между relevance и proximity. \n",
    "        time_func_to (Callable[Tuple[datetime, datetime], int]): подсчет разницы между временами, переведенными в года/месяца.\n",
    "        \n",
    "    Returns:\n",
    "        C_res (List): расширенное сообщество.\n",
    "    \"\"\"\n",
    "    print('start')\n",
    "    subattrs = list(author_first_store[core_member]['keywords'].keys())\n",
    "    C_res = []\n",
    "    for subattr in tqdm(subattrs):\n",
    "        \n",
    "        C = [core_detecting(core_member, attr, subattr, adj_matrix, S_matrix, psi, time_func_to)]\n",
    "        N_C_init = N_a2(C, adj_matrix)\n",
    "        iter = 1\n",
    "        while True:\n",
    "            com_size = len(C)\n",
    "            # print(\"\\n\")\n",
    "            # print(f\"=====Итерация №{iter}=====\")\n",
    "            for v in N_C_init:\n",
    "                # print(f\"---проверка вершины v = {v}---\")\n",
    "                if subattr in author_first_store[v][attr]:\n",
    "                    cand_v = get_candidate(v, attr, subattr, adj_matrix, S_matrix, psi, time_func_to)\n",
    "                    if cand_v in C: # node relation strength\n",
    "                        # print(f\"кандидат вершины лежит в C, добавляем вершину: C = {C} \\n v = {v}\")\n",
    "                        C = C + [v]\n",
    "                    # print(C)\n",
    "                    else: # community relation strength\n",
    "                        # print(f\"кандидат вершины не лежит в C, проверяем CRS\")\n",
    "                        # print(0)\n",
    "                        crs_c = CRS(v, C, attr, subattr, adj_matrix, S_matrix, psi, time_func_to)\n",
    "                        # print(crs_c)\n",
    "                        # print(1)\n",
    "                        C_conj = list(set(authors_) - set(C)) \n",
    "                        crs_conj_c = CRS(v, C_conj, attr, subattr, adj_matrix, S_matrix, psi, time_func_to)\n",
    "                        # print(2) \n",
    "                        if crs_c > crs_conj_c:\n",
    "                            # print(f\"CRS кандидата v и сообщества С больше, чем CRS дополнения, добавляем вершину: C = {C} \\n v = {v}\")\n",
    "                            C = C + [v]\n",
    "                        # else:\n",
    "                            # print(f\"CRS дополнения больше, CRS сообщества для вершины v, v не добавлена в C\")\n",
    "                # else:\n",
    "                    # print('У вершины v нет данного аттрибута, итерация пропущена.')\n",
    "            if len(C) == com_size:\n",
    "                # print(\"Итерация цикла не привела к увеличению C, процесс завершен.\")\n",
    "                break\n",
    "            else:\n",
    "               # print(\"Итерация цикла завершена, сообщество увеличилось, формируем новое дополнение к сообществу C\") \n",
    "               N_C_init = N_a2(C, adj_matrix)\n",
    "            iter += 1\n",
    "            # print(\"\\n\")\n",
    "        C_res.extend(C)\n",
    "    return C_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357d50b-d13b-40e1-97ea-dc188e80b282",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "3ed38631-f39e-443c-9614-663673c71f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модулярность M(F)\n",
    "def modularity_M(F: tp.List, weights: pd.DataFrame) -> float:\n",
    "    \"\"\"Метрика герметичности сообщества, сравнение силы внутреннего соединения и силы соединениядвух узлов в сообществе, когда оно выбрано случайным образом. Чем больше значение метрики, тем лучше.\n",
    "\n",
    "    Args:\n",
    "        F (List): cообщество авторов.\n",
    "        weights (DataFrame): матрица сходности W авторов по временнным и атрибутным связям.\n",
    "\n",
    "    Returns:\n",
    "        Q_m (float): значение метрики.\n",
    "    \"\"\"\n",
    "    # pairs = combinations(F, 2)\n",
    "    w = W_frame.loc[F, F].sum().sum()\n",
    "    Q_m = 0\n",
    "    for a1 in tqdm(F):\n",
    "        for a2 in F:\n",
    "            if a1 == a2: continue\n",
    "            Q_m += 1 / (2 * w) * (weights.loc[a1, a2] - np.dot(weights.loc[:, a2], weights.loc[a1, :]) / (2 * w))\n",
    "    return Q_m\n",
    "    # 1 / (2 * w) * np.sum([weights.loc[a1, a2] - np.dot(weights.loc[:, a2], weights.loc[a1, :]) / (2 * w) for a1, a2 in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d08bf866-0920-4263-84ce-fcb97f8c6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume(F: tp.List, adj_matrix: pd.DataFrame) -> int:\n",
    "    \"\"\"Подсчет степеней вершин сообщества F.\n",
    "    \n",
    "    Args:\n",
    "        F (List): cообщество авторов.\n",
    "        adj_matrix (DataFrame):  матрица смежности авторов по их публикациям.\n",
    "\n",
    "    Returns:\n",
    "        vol (int): сумма степеней вершин сообщества F.\n",
    "    \"\"\"\n",
    "    vol = 0\n",
    "    for author in F:\n",
    "        vol += adj_matrix.loc[author, :].sum()\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "35b62615-0c7f-41a3-9dc7-bcadff030d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_cut(F: tp.List, authors: tp.List, weights: pd.DataFrame) -> float:\n",
    "    \"\"\"Отношение связности вершин внутри сообщества к вершинам вне сообщества.\n",
    "    Args:\n",
    "        F (List): cообщество авторов.\n",
    "        authors (List): список всех авторов с их ФИО.\n",
    "        weights (DataFrame): матрица сходности W авторов по временнным и атрибутным связям.\n",
    "\n",
    "    Returns:\n",
    "        pcut (int): значение метрики.\n",
    "    \"\"\"\n",
    "    not_F = list(set(authors) - set(F))\n",
    "    pcut = 0\n",
    "    for a1 in F:\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        for a2 in not_F:\n",
    "            sum_1 += weights.loc[a1, a2] \n",
    "        for a2 in F:\n",
    "            sum_2 += weights.loc[a1, a2] \n",
    "        pcut += sum_1 / sum_2\n",
    "    return pcut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "fdeb1d65-bbca-4ae5-8c2f-9f71182f1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cond_metric(F: tp.List, authors: tp.List, weights: pd.DataFrame, adj_matrix: pd.DataFrame) -> float:\n",
    "    \"\"\"Метрика плотности множества вершин в сообществе.\n",
    "    \n",
    "    Args:\n",
    "        F (List): cообщество авторов.\n",
    "        authors (List): список всех авторов с их ФИО.\n",
    "        weights (DataFrame): матрица сходности W авторов по временнным и атрибутным связям.\n",
    "        adj_matrix (DataFrame):  матрица смежности авторов по их публикациям.\n",
    "\n",
    "    Returns:\n",
    "        (float): значение метрики.\n",
    "    \"\"\"\n",
    "    return P_cut(F, authors_, weights) / volume(F, adj_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d862cc-26c9-414e-9c81-c2e4a4f1e2f8",
   "metadata": {},
   "source": [
    "### Графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e51ceeb4-bd54-4daf-812e-6cc6e36fcba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_visualize(core_member: str, F: tp.List, adj_matrix: pd.DataFrame) -> None:\n",
    "    graph_nodes_C = list(set(C_res)) \n",
    "    graph_nodes_N = list(set(N_a_func(core_member).index))\n",
    "    \n",
    "    adj_matrix_C = adj_matrix.loc[graph_nodes_C, graph_nodes_C]\n",
    "    adj_matrix_N = adjacency_matrix.loc[graph_nodes_N, graph_nodes_N]\n",
    "    \n",
    "    authors_nodes = adj_matrix.columns\n",
    "    \n",
    "    authors2nodes = dict(zip(authors_nodes, list(range(len(adj_matrix)))))\n",
    "    nodes2authors = {v: k for k, v in nodes2authors.items()}\n",
    "    \n",
    "    authors_nodes_recommended = list(set(graph_nodes_C) - set(graph_nodes_N))\n",
    "\n",
    "    edges_C = []\n",
    "    for idx_1 in range(len(adj_matrix_C.values)):\n",
    "        for idx_2 in range(idx_1, len(adj_matrix_C.values)):\n",
    "            if idx_1 == idx_2: continue\n",
    "            if adj_matrix_C.values[idx_1, idx_2] == 1:\n",
    "                edges.append((authors_nodes[idx_1], authors_nodes[idx_2], {'color': 'red', 'weight': 1}))\n",
    "        \n",
    "    edges_N = []\n",
    "    for idx_1 in range(len(adj_matrix_N.values)):\n",
    "        for idx_2 in range(idx_1, len(adj_matrix_N.values)):\n",
    "            if idx_1 == idx_2: continue\n",
    "            if adj_matrix_N.values[idx_1, idx_2] == 1:\n",
    "                edges_N.append((authors_nodes[idx_1], authors_nodes[idx_2]))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list(zip(authors_nodes_recommended, [{\"color\": \"red\"}] * len(authors_nodes_recommended))))\n",
    "    G.add_nodes_from(list(zip(graph_nodes_N,[{\"color\": \"blue\"}] * len(graph_nodes_N))))\n",
    "    colored_dict = nx.get_node_attributes(G, 'color')\n",
    "\n",
    "    edges_by_kw = []\n",
    "    for i in range(len(graph_nodes_C)):\n",
    "        for j in range(i, len(graph_nodes_C)):\n",
    "            if i == j: continue\n",
    "            weight = len(set(author_first_store[graph_nodes_C[i]]['keywords'].keys()) & set(author_first_store[graph_nodes_C[j]]['keywords'].keys()))\n",
    "            if weight > 0:\n",
    "                edges_by_kw.append((graph_nodes_C[i], graph_nodes_C[j], {'color': 'green', 'weight': weight*0.1}))\n",
    "\n",
    "    edges_by_kw = [i for i in edges_by_kw if (i[0], i[1]) not in edges_C]\n",
    "\n",
    "    G.add_edges_from(edges_by_kw + edges_C)\n",
    "\n",
    "    color_edges = nx.get_edge_attributes(G, 'color')\n",
    "    weight_edges = nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "    fig = plt.figure(3, figsize=(16, 16), dpi=80)\n",
    "    nx.draw_spring(G, with_labels=True, font_size=18, font_weight='bold', node_color=list(colored_dict.values()),\n",
    "                   edge_color=list(color_edges.values()), width=list(weight_edges.values()))\n",
    "    \n",
    "    plt.savefig(f'graph_{core_member}.png')\n",
    "\n",
    "# | set(N_a_func(core_member).index))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "fe20c134-67ef-4278-9221-7f14f62e3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity_graphic(F: tp.List, core_member: str, authors: tp.List, adj_matrix: np.array, weight: pd.DataFrame) -> None:\n",
    "    N_a = list(N_a_func(core_member, adj_matrix).index)\n",
    "    N_a_list = []\n",
    "    # Q_m = modularity_Q(N_a_list, W_frame)\n",
    "    not_N_a = set(F) - set(N_a)\n",
    "    values_M = []\n",
    "    \n",
    "    for node in tqdm(N_a_list):\n",
    "        N_a_list.append(node)\n",
    "        values_M.append(modularity_M(N_a_list, weight))\n",
    "        \n",
    "    for node in not_N_a:\n",
    "        N_a_list.append(node)\n",
    "        values_M.append(modularity_M(N_a_list, weight))\n",
    "        \n",
    "    bad_nodes = np.random.choice(list(set(authors) - set(N_a_list)), 100, replace=False)\n",
    "    \n",
    "    for node in bad_nodes:\n",
    "        N_a_list.append(node)\n",
    "        values_M.append(modularity_M(N_a_list, weight))\n",
    "\n",
    "    plt.plot(values_M, label='динамика M(x)')\n",
    "    # plt.plot([23,23], [0.08, 0.25], color='red')\n",
    "    plt.scatter([len(N_a) - 1], [values_M[len(N_a) - 1]], color='green', label='M(N(a))')\n",
    "    plt.scatter([len(N_a_list) - 101], [values_M[len(N_a_list) - 101]], color='red', label='M(F)')\n",
    "    plt.xlabel(\"Число авторов\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylabel(\"M(x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "cb1276bb-7720-461e-9326-de51ae7b06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_graphic(F: tp.List, core_member: str, authors: tp.List, adj_matrix: np.array, weight: pd.DataFrame) -> None:\n",
    "    N_a = list(N_a_func(core_member, adj_matrix).index)\n",
    "    N_a_list = []\n",
    "    # Q_m = modularity_Q(N_a_list, W_frame)\n",
    "    not_N_a = set(F) - set(N_a)\n",
    "    values_C = []\n",
    "    \n",
    "    for node in tqdm(N_a_list):\n",
    "        N_a_list.append(node)\n",
    "        values_C.append(Cond_metric(N_a_list, list(authors), weight, adjacency_matrix))\n",
    "        \n",
    "    for node in not_N_a:\n",
    "        N_a_list.append(node)\n",
    "        values_C.append(Cond_metric(N_a_list, list(authors), weight, adjacency_matrix))\n",
    "        \n",
    "    bad_nodes = np.random.choice(list(set(authors) - set(N_a_list)), 100, replace=False)\n",
    "    \n",
    "    for node in bad_nodes:\n",
    "        N_a_list.append(node)\n",
    "        values_C.append(Cond_metric(N_a_list, list(authors), weight, adjacency_matrix))\n",
    "\n",
    "    plt.plot(values_C, label='динамика Cond(x)')\n",
    "    # plt.plot([23,23], [0.08, 0.25], color='red')\n",
    "    plt.scatter([len(N_a) - 1], [values_C[len(N_a) - 1]], color='green', label='Cond(N(a))')\n",
    "    plt.scatter([len(N_a_list) - 101], [values_C[len(N_a_list) - 101]], color='red', label='Cond(F)')\n",
    "    plt.xlabel(\"Число авторов\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylabel(\"Cond(x)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
